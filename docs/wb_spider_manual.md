## Weibo Spider Manual

### Initialize 

**1. Initialize docker container:** 
The container is mounted from image `mongoDB_wb`, used as a database of spider. 

**2. Create Weibo Spider**
```shell
sudo chmod 755 ./init/init_wb.sh
./init/init_wb.sh
```

`init_wb.sh` will create the necessary configurations and mapped directories for `mongoDB_wb` in the docker container.  The data is stored in `Home/mongoDB_wb`


**3. Initialize the Weibo database:**

Thenï¼Œaccording to the hint of`init_wb.sh`ï¼Œwe need to execute the following command to call the script `db_init_wb.js`ï¼Œ which is used to initialize the database.

```shell
sudo docker exec -it wb_spider mongo 127.0.0.1:27018 /etc/resource/db_init_wb.js
```

`db_init_wb.js` will create 2 users respectively: `admin`(administrator) and `weibo`(usual user)ï¼Œand 6 tables `user`,`user_post`, `tag_post`, `review` and `error_log`.


> **NB**:  You will be asked to input your own password when you create the `admin` and `weibo`.


**4.Modify the params**

Rewrite `./wb_spider/database/DBconnector.py`ï¼Œmodify the `mongo_pwd` in function `__init__` to your own passwordï¼Œwhich is used for Spider to connect to the databaseã€‚

```python
def __init__(self):
  self.mongo_uri = "127.0.0.1:27018" # IP used to connect with Docker.
  self.mongo_database = "weibo" # database created from init_db.js
  self.mongo_user_name = "weibo" # the user in database 'weibo'
  self.mongo_pass_wd = "Your password."
```

### Start

#### With terminal command

There are 4 spiders available now, and the corresponding commands are as follow:

|  Spider Name   |                    CMD                     |                           Function                           |
| :------------: | :----------------------------------------: | :----------------------------------------------------------: |
| `wb_spider` | `scrapy crawl wb_spider -a uid=xxx&verbar;xxx` | Collecting the target usersâ€™ information and all blog posts, which must be introduced `-a uid = xxx &verbar; xxx"` (the target collection user's `UID`) |
| `user_spider`  | `scrapy crawl user_spdier -a uid=xxx&verbar;xxx`  | Collect the target usersâ€™ informationï¼Œ parameters are the same as`weibo_spider`. |
| `user_post_spider`  | `scrapy crawl user_post_spider -a uid=xxx&verbar;xxx`  | Collect all the blog posts of the target users, parameters are the same as`wb_spider`. |
| `tag_post_spider`  | `scrapy crawl tag_post_spider -a uid=xxx&verbar;xxx`  | Collect all the blog posts of the target hashtag and reviews of each post, parameters `uid` should be `%23[keyword]`, such as `%23é™•è¥¿` (the whole command is `scrapy crawl tag_post_spider -a uid="%23é™•è¥¿"`). |

#### With Python Script

According to the [command line tool of scrapy](https://doc.scrapy.org/en/latest/topics/commands.html?highlight=scrapy%20crawl), we can execute `cmd` command with python to call the sprider:

```python
from scrapy.cmdline import execute

if __name__ == '__main__':
    spider_cmd = "scrapy crawl wb_spider -a uid=user1_id|user2_id|...."
    execute(spider_cmd.split())
    
```



### File Tree Structure

```
ğŸ“¦wb_spider
 â”£ ğŸ“‚base
 â”ƒ â”£ ğŸ“œBaseConfig.py
 â”ƒ â”£ ğŸ“œBaseSpider.py
 â”ƒ â”£ ğŸ“œPipeline.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“‚config
 â”ƒ â”£ ğŸ“œReviewConfig.py
 â”ƒ â”£ ğŸ“œTagPostConfig.py
 â”ƒ â”£ ğŸ“œUserConfig.py
 â”ƒ â”£ ğŸ“œUserPostConfig.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“‚database
 â”ƒ â”£ ğŸ“œDBConnector.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“‚items
 â”ƒ â”£ ğŸ“œErrorItem.py
 â”ƒ â”£ ğŸ“œLongtextItem.py
 â”ƒ â”£ ğŸ“œReviewItem.py
 â”ƒ â”£ ğŸ“œTagPostItem.py
 â”ƒ â”£ ğŸ“œUserItem.py
 â”ƒ â”£ ğŸ“œUserPostItem.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“‚middlewares
 â”ƒ â”£ ğŸ“œDepthMiddleware.py
 â”ƒ â”£ ğŸ“œFakeUserAgentMiddleware.py
 â”ƒ â”£ ğŸ“œInitialMiddleware.py
 â”ƒ â”£ ğŸ“œProxyMiddleware.py
 â”ƒ â”£ ğŸ“œRetryMiddleware.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“‚pipelines
 â”ƒ â”£ ğŸ“œErrorPipeline.py
 â”ƒ â”£ ğŸ“œLongtextPipeline.py
 â”ƒ â”£ ğŸ“œReviewPipeline.py
 â”ƒ â”£ ğŸ“œTagPostPipeline.py
 â”ƒ â”£ ğŸ“œUserPipeline.py
 â”ƒ â”£ ğŸ“œUserPostPipeline.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“‚resource
 â”ƒ â”— ğŸ“œ0.1.11.json
 â”£ ğŸ“‚spiders
 â”ƒ â”£ ğŸ“‚_spider
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”ƒ â”£ ğŸ“œtag_post_spider.py
 â”ƒ â”ƒ â”£ ğŸ“œuser_info_spider.py
 â”ƒ â”ƒ â”— ğŸ“œuser_post_spider.py
 â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”— ğŸ“œwb_spider.py
 â”£ ğŸ“œ__init__.py
 â”— ğŸ“œsettings.py
```